# NAACL-2018
There was so much happening at NAACL; so many interesting works on all sorts of (old and new) NLP problems. Lots of papers focused on how to generalize the models beyond the conditions during training. In addition, there was workshop on “New Forms of Generalization in Deep Learning and Natural Language Processing”. In that workshop, Yejin Choi pointed out  that natural language understanding (NLU) does not generalize to natural language generation (NLG). Another focus of the conference/workshops were on dialogue systems and chatbots. Lots of talks focused on using a knowledge graph in chatbots to have deeper conversations without staying on the topic for the whole conversations. 


I’ll start with keynotes which are more high-level, and then I summarize some of the technical talks and posters.
In case you’re interested, I highly recommend the paper [“Deep Contextualized Word Representations”](https://allennlp.org/elmo) which won the best paper award by AI2

##Keynotes:
Why 72? (by Charles Yang - Upenn):
This was a **great** talk. He started with a simple question: “Why do Chinese-speaking kids (i.e., 2-3 year olds) learn to count faster than English-speaking kids?”. Apparently, an English-speaking kid can count up to 100 once they know how to count to 72. The corresponding number is about 40 for Chinese. He explained that this has to do with how we learn language rules (and their exceptions). Obviously, exceptions make it difficult for any system to learn the rules (e.g., “fifteen” instead of “fiveteen”). His work provides (theoretical and experimental) evidence that humans learn a rule if there are at most “n / ln(n)” exceptions in “n” observed samples. Using this, you can explain the numbers 72 and 40. This is all cool, but why should we care? Well, he then focused on a few rules of language (for instance, the fact that both “a” and “the” can precede a noun), and showed that in a natural (large) corpus only 30% of nouns appear with both “a” and “the”. He found this disturbing since according to his model, humans should not generalize that nouns can appear with either “a” or “the”. So why do we generalize? It turns out that we learn this rule when we only know about 3000 words, and these limited set of words commonly appear with both “a” and “the”. Thus, when we only know 3000 words, it’s easier for us to figure out the rule. In other words, not knowing many words is a blessing. Based on this, he concluded the talk by suggesting the NLP community to use less (and more limited) data! He believes most of what we want (and need) to learn can be learned from simpler and more limited data. 

Building a SocialBot: Lessons Learned from 10M Conversations (by Mari Ostendorf - University of Washington):
Her lab was the winner of the Alexa SocialBot challenge, and this walk was basically a summary of what they learned during the challenge. She shared many funny examples of what may go wrong in these systems and I’ll promise to include one in the end. Here are some of the points from the talk:
  * Seq2seq models are really good at saying “I don’t know”, so use “rule-based” techniques specially if you are launching a new system and have no clue how users might interact with your system. Rule-based chatbots can help you gather the data you need to bootstrap. 
  * People enjoy chatting if (1) you have something interesting to say, and (2) you show interest in them (even if it’s as subtle as acknowledging their response in a smarter way).
  *   * Doing (1) from the previous bullet is very challenging. You need to fetch interesting facts and information from relevant sources, understand them, and incorporate them appropriately into the conversation. 
  * It’s important to classify your user. Are you talking to a kid? An adversarial user? etc. 
  * In their experience, the best design for a dialogue manager consists of a “master dialogue manager” which delegates the conversation to more specialized dialogue systems.
  * Finally, they mentioned that it is extremely hard to have deep conversations. Most exchanges are short and they had to move on to a different topic to keep the conversation going.
Here is one of the funny examples she presented. This is a conversation between the bot and a small kid (from a kindergarten they were presenting the bot at):
